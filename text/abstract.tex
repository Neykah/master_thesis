\begin{abstract}
Action recognition is a useful yet extremely difficult task in computer vision. It aims at making computers able to understand actions performed by humans. This task is particularly important in robotics in order to develop multitasks robots such as domestic assistant robots. These types of robots indeed need to be aware of their environment in real time and analysing the actions conducted by their owner is one condition to achieve that awareness. 

However, such analysis is often difficult to conduct for different reasons. First, the human brain behaviour itself is still mysterious on such matters: human people tend to use a lot of implicit contextual information to describe an action, making use not only of the posture of the person involved, but considering the environment in which this human evolves. Second, the algorithms usually involved in action detection are often based on very deep models, and therefore are not always computable in real time, making them irrelevant to robotics application. Finally, these algorithms mainly provide supervised action recognition, creating a need for huge labeled video dataset which are extremely costly to make, to only achieve detection a few specific classes. On the other hand, unsupervised video dataset have become very easy to find and unsupervised action recognition can create a lot more of different clusters of actions.

In this work, we propose an architecture of robotics software platform in order to tackle real time unsupervised action recognition by using spatial context information. We perform naive detection without context information, implement 3D mapping and spatial context in our model, and describe the advantages induced by that technique.

\end{abstract}