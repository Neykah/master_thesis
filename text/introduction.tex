\chapter{Introduction}

In this work, we try to perform unsupervised action recognition based on spatial context information in a domestic robot environment. In this section, we will describe the exact task and its context, before defining the objectives of this study and introducing our contribution.

\section{Background and Related Works}
\subsection{Action Recognition}
Action recognition and detection is a major problem in computer vision \cite{review_action_recognition}. It has been an active research field since the 1990s \cite{plan_recognition}, but has dramatically gained attention like most of the other computer vision tasks in the 2010s, as the performance of these techniques improved a lot with generalisation of deep learning and appearance of easily obtainable large scale datasets.

The proper goal of action recognition is, given a visual input consisting of a single frame or a video, to predict a classification result for the actions in this input. Formally speaking, another field of research named action detection also exist. Its goal is to locate one or a set of actions of interest in both space and time, for instance by outputting Region Of Interest (ROI) corresponding to each detected action on the input frames.
This distinction between recognition and detection is similar to the one existing in the field of object classification/detection for instance, however in practice it is often ignored in the literature as most modern algorithms try to carry both tasks. For the scope of this thesis, we will therefore call Action Recognition both the tasks of action recognition and action detection.

Like most machine learning applications, action recognition can be roughly divided in two different categories: supervised and unsupervised. Supervised action recognition makes use of a labeled video dataset \cite{hollywood2,sports_video_dataset,ActivityNet} to detect a limited amount of actions and classify them explicitly. These types of algorithms achieve state of the art accuracy on benchmarks based on the aforementioned datasets. However, labeled video datasets are quite difficult to find since the labeling process is really heavy. They also only focus on a few specific action classes, such as actions in sports for instance. Another flaw of these datasets is that even if their size in term of number of frames may seem huge, a lot of these frames actually come from the same video, resulting in a poor diversity among these frames.

On the other hand, unsupervised action recognition algorithms try to achieve the same task without using a labeled dataset. Its main advantage is that it can make use of a far wider range of datasets such as ones based on Youtube\footnote{http://www.youtube.com} videos, which can lead these algorithms to generalize better. However, since their input dataset is not labeled, they cannot issue an explicit classification of the different actions performed, but instead output a set of clusters of actions. These clusters may then be classified afterward in order to test these algorithms on labeled benchmarks, but this only reveal a small part of the knowledge acquired by the trained models.



\subsection{Domestic Robot Environment}
The software described in this work is supposed to be used in a domestic robot environment. We describe here what we mean by using that term.

A domestic robot is a type of indoor service robot that is mainly used for house chores, housekeeping, but also entertainment or therapy.
As opposed to industrial robots, which are designed to carry out a limited amount of specific tasks in well-designated environment such as a production chain in a factory or a warehouse, domestic robot need to be more generalist.

Indeed, they should be able to evolve in the small and somewhat chaotic environment that are individual apartments or houses. Since they are also designed to assist their owners in tasks from everyday life, they need to be more flexible and to adapt to a large number of situations.

A lot of work has already been done in order to make robots transition from facilities to private housings. Some of then focus on finding a good 3D representation of complex environments and operate "basic" analysis to detect navigable paths in these representations \cite{SLAM_review,loop-closure}. Other works attempt to break these maps into smaller meaningful parts by performing recognition and segmentation in quite different ways that what is done on images data \cite{plan_recognition,region_growing_seg, pointcloud_clustering}. Finally, others try to extract semantic meaning from these parts using various criteria \cite{action_map_first_person, semantic_pointcloud}.

\section{Objectives}
The goal of this work is primarily to implement action recognition on a domestic robot. Considering the chaotic and diverse environment in which that domestic robot evolves, and since there is currently no labeled dataset of videos containing action diverse enough to be realistically used to detect domestic actions, we decided in the beginning to use unsupervised clustering applied to the output of a body part detection algorithm to tackle this task. The output of this workflow is a set of static human pose clusters. 

From there, the main trend in the literature is to make use of the temporal consistency of the videos to refine the action clustering \cite{unsup_time_seq_action_recognition, action_matching}. However, since we work with a robot we have access to a lot more of spatial context data, like depth and odometry. Therefore, we decided to focus on the use of these spatial features to improve the action clustering.

\section{Contributions}
The main contribution of this work is the development of a complete robotics platform for action recognition using spatial context. By using it, one can simultaneously perform the tasks of robot control, point cloud generation, environment mapping and navigation, registration of the history of human/environment interactions - what we call an \emph{action map} - and finally action recognition.

This platform is built on top of ROS \cite{ROS}, a widely distributed open-source framework for robotics programming. ROS programs, also called nodes, are by nature supposed to work in real-time on a network and therefore this work is easily generalisable to a wide range of configurations, which can for example include long distance control or parallel processing of multiple robots.

An additional contribution resides in our experiments and results. They contribute to the understanding of the advantages and limit of spatial context informations for unlabeled action recognition, a field that was in the limit of our knowledge almost not studied in the past. 

\section{Outline}
The rest of this document is structured as follows. In chapter \ref{chap:archi} we introduce our proposed workflow architecture to tackle this problem given our work environment and describe the current implementation of the system. In chapter \ref{chap:experiments} we report the experiments we conducted on the platform and discuss the obtained results. We conclude and introduce proposals of future work in chapter \ref{chap:conclusion}. 